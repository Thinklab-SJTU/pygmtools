
.. DO NOT EDIT.
.. THIS FILE WAS AUTOMATICALLY GENERATED BY SPHINX-GALLERY.
.. TO MAKE CHANGES, EDIT THE SOURCE PYTHON FILE:
.. "auto_examples/6.image_matching_by_QAP/plot_image_matching_pytorch.py"
.. LINE NUMBERS ARE GIVEN BELOW.

.. only:: html

    .. note::
        :class: sphx-glr-download-link-note

        :ref:`Go to the end <sphx_glr_download_auto_examples_6.image_matching_by_QAP_plot_image_matching_pytorch.py>`
        to download the full example code

.. rst-class:: sphx-glr-example-title

.. _sphx_glr_auto_examples_6.image_matching_by_QAP_plot_image_matching_pytorch.py:


================================================================
PyTorch Backend Example: Matching Image Keypoints by QAP Solvers
================================================================

This example shows how to match image keypoints by graph matching solvers provided by ``pygmtools``.
These solvers follow the Quadratic Assignment Problem formulation and can generally work out-of-box.
The matched images can be further processed for other downstream tasks.

.. GENERATED FROM PYTHON SOURCE LINES 11-16

.. code-block:: default


    # Author: Runzhong Wang <runzhong.wang@sjtu.edu.cn>
    #
    # License: Mulan PSL v2 License








.. GENERATED FROM PYTHON SOURCE LINES 18-29

.. note::
    The following solvers support QAP formulation, and are included in this example:

    * :func:`~pygmtools.classic_solvers.rrwm` (classic solver)

    * :func:`~pygmtools.classic_solvers.ipfp` (classic solver)

    * :func:`~pygmtools.classic_solvers.sm` (classic solver)

    * :func:`~pygmtools.neural_solvers.ngm` (neural network solver)


.. GENERATED FROM PYTHON SOURCE LINES 29-42

.. code-block:: default

    import torch # pytorch backend
    import torchvision # CV models
    import pygmtools as pygm
    import matplotlib.pyplot as plt # for plotting
    from matplotlib.patches import ConnectionPatch # for plotting matching result
    import scipy.io as sio # for loading .mat file
    import scipy.spatial as spa # for Delaunay triangulation
    from sklearn.decomposition import PCA as PCAdimReduc
    import itertools
    import numpy as np
    from PIL import Image
    pygm.set_backend('pytorch') # set default backend for pygmtools








.. GENERATED FROM PYTHON SOURCE LINES 43-50

Load the images
----------------
Images are from the Willow Object Class dataset (this dataset also available with the Benchmark of ``pygmtools``,
see :class:`~pygmtools.dataset.WillowObject`).

The images are resized to 256x256.


.. GENERATED FROM PYTHON SOURCE LINES 50-62

.. code-block:: default

    obj_resize = (256, 256)
    img1 = Image.open('../data/willow_duck_0001.png')
    img2 = Image.open('../data/willow_duck_0002.png')
    kpts1 = torch.tensor(sio.loadmat('../data/willow_duck_0001.mat')['pts_coord'])
    kpts2 = torch.tensor(sio.loadmat('../data/willow_duck_0002.mat')['pts_coord'])
    kpts1[0] = kpts1[0] * obj_resize[0] / img1.size[0]
    kpts1[1] = kpts1[1] * obj_resize[1] / img1.size[1]
    kpts2[0] = kpts2[0] * obj_resize[0] / img2.size[0]
    kpts2[1] = kpts2[1] * obj_resize[1] / img2.size[1]
    img1 = img1.resize(obj_resize, resample=Image.BILINEAR)
    img2 = img2.resize(obj_resize, resample=Image.BILINEAR)








.. GENERATED FROM PYTHON SOURCE LINES 63-65

Visualize the images and keypoints


.. GENERATED FROM PYTHON SOURCE LINES 65-80

.. code-block:: default

    def plot_image_with_graph(img, kpt, A=None):
        plt.imshow(img)
        plt.scatter(kpt[0], kpt[1], c='w', edgecolors='k')
        if A is not None:
            for idx in torch.nonzero(A, as_tuple=False):
                plt.plot((kpt[0, idx[0]], kpt[0, idx[1]]), (kpt[1, idx[0]], kpt[1, idx[1]]), 'k-')

    plt.figure(figsize=(8, 4))
    plt.subplot(1, 2, 1)
    plt.title('Image 1')
    plot_image_with_graph(img1, kpts1)
    plt.subplot(1, 2, 2)
    plt.title('Image 2')
    plot_image_with_graph(img2, kpts2)




.. image-sg:: /auto_examples/6.image_matching_by_QAP/images/sphx_glr_plot_image_matching_pytorch_001.png
   :alt: Image 1, Image 2
   :srcset: /auto_examples/6.image_matching_by_QAP/images/sphx_glr_plot_image_matching_pytorch_001.png
   :class: sphx-glr-single-img





.. GENERATED FROM PYTHON SOURCE LINES 81-86

Build the graphs
-----------------
Graph structures are built based on the geometric structure of the keypoint set. In this example,
we refer to `Delaunay triangulation <https://en.wikipedia.org/wiki/Delaunay_triangulation>`_.


.. GENERATED FROM PYTHON SOURCE LINES 86-97

.. code-block:: default

    def delaunay_triangulation(kpt):
        d = spa.Delaunay(kpt.numpy().transpose())
        A = torch.zeros(len(kpt[0]), len(kpt[0]))
        for simplex in d.simplices:
            for pair in itertools.permutations(simplex, 2):
                A[pair] = 1
        return A

    A1 = delaunay_triangulation(kpts1)
    A2 = delaunay_triangulation(kpts2)








.. GENERATED FROM PYTHON SOURCE LINES 98-100

We encode the length of edges as edge features


.. GENERATED FROM PYTHON SOURCE LINES 100-105

.. code-block:: default

    A1 = ((kpts1.unsqueeze(1) - kpts1.unsqueeze(2)) ** 2).sum(dim=0) * A1
    A1 = (A1 / A1.max()).to(dtype=torch.float32)
    A2 = ((kpts2.unsqueeze(1) - kpts2.unsqueeze(2)) ** 2).sum(dim=0) * A2
    A2 = (A2 / A2.max()).to(dtype=torch.float32)








.. GENERATED FROM PYTHON SOURCE LINES 106-108

Visualize the graphs


.. GENERATED FROM PYTHON SOURCE LINES 108-116

.. code-block:: default

    plt.figure(figsize=(8, 4))
    plt.subplot(1, 2, 1)
    plt.title('Image 1 with Graphs')
    plot_image_with_graph(img1, kpts1, A1)
    plt.subplot(1, 2, 2)
    plt.title('Image 2 with Graphs')
    plot_image_with_graph(img2, kpts2, A2)




.. image-sg:: /auto_examples/6.image_matching_by_QAP/images/sphx_glr_plot_image_matching_pytorch_002.png
   :alt: Image 1 with Graphs, Image 2 with Graphs
   :srcset: /auto_examples/6.image_matching_by_QAP/images/sphx_glr_plot_image_matching_pytorch_002.png
   :class: sphx-glr-single-img





.. GENERATED FROM PYTHON SOURCE LINES 117-121

Extract node features
----------------------
Let's adopt the VGG16 CNN model to extract node features.


.. GENERATED FROM PYTHON SOURCE LINES 121-128

.. code-block:: default

    vgg16_cnn = torchvision.models.vgg16_bn(True)
    torch_img1 = torch.from_numpy(np.array(img1, dtype=np.float32) / 256).permute(2, 0, 1).unsqueeze(0) # shape: BxCxHxW
    torch_img2 = torch.from_numpy(np.array(img2, dtype=np.float32) / 256).permute(2, 0, 1).unsqueeze(0) # shape: BxCxHxW
    with torch.set_grad_enabled(False):
        feat1 = vgg16_cnn.features(torch_img1)
        feat2 = vgg16_cnn.features(torch_img2)





.. rst-class:: sphx-glr-script-out

 .. code-block:: none

    Downloading: "https://download.pytorch.org/models/vgg16_bn-6c64b313.pth" to /home/wzever/.cache/torch/hub/checkpoints/vgg16_bn-6c64b313.pth
      0%|          | 0.00/528M [00:00<?, ?B/s]      0%|          | 80.0k/528M [00:00<14:27, 638kB/s]      0%|          | 272k/528M [00:00<06:54, 1.34MB/s]      0%|          | 744k/528M [00:00<03:16, 2.81MB/s]      0%|          | 1.87M/528M [00:00<01:28, 6.23MB/s]      1%|          | 4.32M/528M [00:00<00:42, 12.9MB/s]      1%|▏         | 6.61M/528M [00:00<00:33, 16.5MB/s]      2%|▏         | 9.23M/528M [00:00<00:27, 20.0MB/s]      2%|▏         | 12.1M/528M [00:00<00:23, 22.6MB/s]      3%|▎         | 14.9M/528M [00:00<00:22, 23.9MB/s]      3%|▎         | 17.8M/528M [00:01<00:20, 25.6MB/s]      4%|▍         | 20.4M/528M [00:01<00:20, 26.2MB/s]      4%|▍         | 23.7M/528M [00:01<00:18, 28.3MB/s]      5%|▌         | 27.2M/528M [00:01<00:17, 30.8MB/s]      6%|▌         | 30.6M/528M [00:01<00:16, 32.2MB/s]      6%|▋         | 33.7M/528M [00:01<00:16, 32.0MB/s]      7%|▋         | 36.8M/528M [00:01<00:17, 30.2MB/s]      8%|▊         | 40.4M/528M [00:01<00:15, 32.4MB/s]      8%|▊         | 43.5M/528M [00:01<00:15, 32.1MB/s]      9%|▉         | 47.1M/528M [00:01<00:14, 33.8MB/s]     10%|▉         | 50.4M/528M [00:02<00:15, 32.1MB/s]     10%|█         | 53.5M/528M [00:02<00:15, 31.3MB/s]     11%|█         | 56.7M/528M [00:02<00:15, 31.8MB/s]     11%|█▏        | 59.7M/528M [00:02<00:17, 28.1MB/s]     12%|█▏        | 63.2M/528M [00:02<00:16, 29.4MB/s]     13%|█▎        | 67.1M/528M [00:02<00:14, 32.5MB/s]     13%|█▎        | 70.5M/528M [00:02<00:14, 33.3MB/s]     14%|█▍        | 73.7M/528M [00:02<00:14, 33.4MB/s]     15%|█▍        | 77.0M/528M [00:02<00:14, 33.5MB/s]     15%|█▌        | 80.2M/528M [00:03<00:14, 31.6MB/s]     16%|█▌        | 83.2M/528M [00:03<00:15, 29.4MB/s]     16%|█▋        | 86.3M/528M [00:03<00:15, 29.6MB/s]     17%|█▋        | 89.8M/528M [00:03<00:14, 31.3MB/s]     18%|█▊        | 93.1M/528M [00:03<00:14, 31.3MB/s]     18%|█▊        | 96.9M/528M [00:03<00:13, 33.4MB/s]     19%|█▉        | 100M/528M [00:03<00:13, 34.3MB/s]      20%|█▉        | 104M/528M [00:03<00:13, 33.2MB/s]     20%|██        | 107M/528M [00:03<00:13, 31.8MB/s]     21%|██        | 110M/528M [00:04<00:14, 30.9MB/s]     21%|██▏       | 113M/528M [00:04<00:14, 29.0MB/s]     22%|██▏       | 116M/528M [00:04<00:15, 28.4MB/s]     23%|██▎       | 119M/528M [00:04<00:14, 30.1MB/s]     23%|██▎       | 123M/528M [00:04<00:14, 29.8MB/s]     24%|██▍       | 126M/528M [00:04<00:13, 31.8MB/s]     25%|██▍       | 130M/528M [00:04<00:13, 31.1MB/s]     25%|██▌       | 133M/528M [00:04<00:13, 31.0MB/s]     26%|██▌       | 136M/528M [00:04<00:13, 30.7MB/s]     26%|██▋       | 139M/528M [00:05<00:13, 30.7MB/s]     27%|██▋       | 142M/528M [00:05<00:13, 31.1MB/s]     27%|██▋       | 145M/528M [00:05<00:13, 30.1MB/s]     28%|██▊       | 148M/528M [00:05<00:13, 29.3MB/s]     29%|██▊       | 151M/528M [00:05<00:12, 31.0MB/s]     29%|██▉       | 155M/528M [00:05<00:11, 32.7MB/s]     30%|██▉       | 158M/528M [00:05<00:12, 31.9MB/s]     30%|███       | 161M/528M [00:05<00:12, 31.6MB/s]     31%|███       | 164M/528M [00:05<00:12, 30.6MB/s]     32%|███▏      | 167M/528M [00:06<00:12, 31.0MB/s]     32%|███▏      | 171M/528M [00:06<00:11, 32.8MB/s]     33%|███▎      | 174M/528M [00:06<00:11, 33.6MB/s]     34%|███▎      | 178M/528M [00:06<00:11, 33.0MB/s]     34%|███▍      | 181M/528M [00:06<00:11, 31.7MB/s]     35%|███▍      | 184M/528M [00:06<00:11, 32.3MB/s]     35%|███▌      | 187M/528M [00:06<00:11, 32.2MB/s]     36%|███▌      | 190M/528M [00:06<00:11, 32.1MB/s]     37%|███▋      | 194M/528M [00:06<00:10, 32.6MB/s]     37%|███▋      | 197M/528M [00:06<00:10, 33.7MB/s]     38%|███▊      | 201M/528M [00:07<00:09, 34.9MB/s]     39%|███▊      | 204M/528M [00:07<00:10, 31.1MB/s]     39%|███▉      | 208M/528M [00:07<00:10, 32.0MB/s]     40%|███▉      | 211M/528M [00:07<00:10, 31.7MB/s]     41%|████      | 214M/528M [00:07<00:10, 32.5MB/s]     41%|████      | 217M/528M [00:07<00:10, 32.2MB/s]     42%|████▏     | 221M/528M [00:07<00:09, 32.9MB/s]     42%|████▏     | 224M/528M [00:07<00:10, 29.6MB/s]     43%|████▎     | 227M/528M [00:07<00:10, 30.6MB/s]     44%|████▎     | 230M/528M [00:08<00:10, 30.9MB/s]     44%|████▍     | 234M/528M [00:08<00:10, 30.6MB/s]     45%|████▍     | 237M/528M [00:08<00:09, 31.7MB/s]     46%|████▌     | 240M/528M [00:08<00:09, 32.6MB/s]     46%|████▌     | 244M/528M [00:08<00:09, 32.6MB/s]     47%|████▋     | 247M/528M [00:08<00:08, 33.7MB/s]     47%|████▋     | 251M/528M [00:08<00:08, 34.5MB/s]     48%|████▊     | 254M/528M [00:08<00:09, 30.4MB/s]     49%|████▊     | 257M/528M [00:09<00:10, 27.6MB/s]     49%|████▉     | 260M/528M [00:09<00:09, 29.3MB/s]     50%|████▉     | 263M/528M [00:09<00:09, 29.9MB/s]     50%|█████     | 266M/528M [00:09<00:09, 29.4MB/s]     51%|█████     | 270M/528M [00:09<00:09, 29.4MB/s]     52%|█████▏    | 273M/528M [00:09<00:09, 28.4MB/s]     52%|█████▏    | 276M/528M [00:09<00:09, 27.6MB/s]     53%|█████▎    | 279M/528M [00:09<00:09, 28.6MB/s]     54%|█████▎    | 283M/528M [00:09<00:08, 30.3MB/s]     54%|█████▍    | 286M/528M [00:10<00:08, 29.7MB/s]     55%|█████▍    | 289M/528M [00:10<00:08, 31.1MB/s]     55%|█████▌    | 293M/528M [00:10<00:07, 32.3MB/s]     56%|█████▌    | 296M/528M [00:10<00:07, 31.2MB/s]     57%|█████▋    | 300M/528M [00:10<00:07, 33.0MB/s]     57%|█████▋    | 303M/528M [00:10<00:07, 32.8MB/s]     58%|█████▊    | 306M/528M [00:10<00:07, 32.4MB/s]     59%|█████▊    | 309M/528M [00:10<00:06, 33.3MB/s]     59%|█████▉    | 313M/528M [00:10<00:06, 32.5MB/s]     60%|█████▉    | 316M/528M [00:11<00:07, 29.9MB/s]     60%|██████    | 319M/528M [00:11<00:14, 15.6MB/s]     61%|██████    | 322M/528M [00:11<00:10, 19.7MB/s]     62%|██████▏   | 326M/528M [00:11<00:09, 22.3MB/s]     62%|██████▏   | 329M/528M [00:11<00:08, 23.9MB/s]     63%|██████▎   | 332M/528M [00:11<00:07, 26.2MB/s]     64%|██████▎   | 336M/528M [00:11<00:06, 29.4MB/s]     64%|██████▍   | 339M/528M [00:12<00:06, 30.3MB/s]     65%|██████▍   | 343M/528M [00:12<00:06, 29.9MB/s]     66%|██████▌   | 346M/528M [00:12<00:05, 32.2MB/s]     66%|██████▌   | 350M/528M [00:12<00:05, 33.0MB/s]     67%|██████▋   | 353M/528M [00:12<00:05, 32.8MB/s]     68%|██████▊   | 357M/528M [00:12<00:05, 32.8MB/s]     68%|██████▊   | 360M/528M [00:12<00:05, 33.6MB/s]     69%|██████▉   | 363M/528M [00:12<00:05, 32.0MB/s]     69%|██████▉   | 366M/528M [00:12<00:05, 31.7MB/s]     70%|███████   | 370M/528M [00:13<00:05, 31.7MB/s]     71%|███████   | 373M/528M [00:13<00:05, 31.5MB/s]     71%|███████   | 376M/528M [00:13<00:04, 32.1MB/s]     72%|███████▏  | 379M/528M [00:13<00:04, 32.3MB/s]     73%|███████▎  | 383M/528M [00:13<00:04, 34.1MB/s]     73%|███████▎  | 386M/528M [00:13<00:04, 33.5MB/s]     74%|███████▍  | 389M/528M [00:13<00:05, 28.3MB/s]     74%|███████▍  | 392M/528M [00:13<00:05, 28.4MB/s]     75%|███████▌  | 396M/528M [00:13<00:04, 31.0MB/s]     76%|███████▌  | 399M/528M [00:14<00:04, 31.1MB/s]     76%|███████▋  | 403M/528M [00:14<00:03, 32.8MB/s]     77%|███████▋  | 406M/528M [00:14<00:03, 33.1MB/s]     78%|███████▊  | 409M/528M [00:14<00:03, 31.2MB/s]     78%|███████▊  | 413M/528M [00:14<00:03, 32.9MB/s]     79%|███████▉  | 416M/528M [00:14<00:03, 33.4MB/s]     80%|███████▉  | 420M/528M [00:14<00:03, 32.0MB/s]     80%|████████  | 424M/528M [00:14<00:03, 33.0MB/s]     81%|████████  | 427M/528M [00:14<00:03, 34.3MB/s]     82%|████████▏ | 431M/528M [00:15<00:03, 33.5MB/s]     82%|████████▏ | 434M/528M [00:15<00:03, 31.6MB/s]     83%|████████▎ | 437M/528M [00:15<00:03, 31.1MB/s]     83%|████████▎ | 440M/528M [00:15<00:03, 29.2MB/s]     84%|████████▍ | 443M/528M [00:15<00:02, 30.3MB/s]     84%|████████▍ | 446M/528M [00:15<00:03, 27.9MB/s]     85%|████████▌ | 449M/528M [00:15<00:02, 28.7MB/s]     86%|████████▌ | 452M/528M [00:15<00:02, 30.4MB/s]     86%|████████▋ | 456M/528M [00:15<00:02, 30.4MB/s]     87%|████████▋ | 459M/528M [00:16<00:02, 29.9MB/s]     88%|████████▊ | 462M/528M [00:16<00:02, 30.3MB/s]     88%|████████▊ | 466M/528M [00:16<00:02, 31.4MB/s]     89%|████████▉ | 469M/528M [00:16<00:01, 31.8MB/s]     90%|████████▉ | 473M/528M [00:16<00:01, 32.6MB/s]     90%|█████████ | 476M/528M [00:16<00:01, 33.7MB/s]     91%|█████████ | 480M/528M [00:16<00:01, 33.0MB/s]     91%|█████████▏| 483M/528M [00:16<00:01, 31.8MB/s]     92%|█████████▏| 486M/528M [00:16<00:01, 31.9MB/s]     93%|█████████▎| 489M/528M [00:17<00:01, 31.3MB/s]     93%|█████████▎| 493M/528M [00:17<00:01, 31.8MB/s]     94%|█████████▍| 496M/528M [00:17<00:01, 30.1MB/s]     94%|█████████▍| 499M/528M [00:17<00:01, 29.9MB/s]     95%|█████████▌| 502M/528M [00:17<00:00, 32.2MB/s]     96%|█████████▌| 506M/528M [00:17<00:00, 33.5MB/s]     96%|█████████▋| 509M/528M [00:17<00:00, 32.7MB/s]     97%|█████████▋| 512M/528M [00:17<00:00, 32.8MB/s]     98%|█████████▊| 515M/528M [00:17<00:00, 31.6MB/s]     98%|█████████▊| 519M/528M [00:18<00:00, 32.4MB/s]     99%|█████████▉| 522M/528M [00:18<00:00, 32.3MB/s]     99%|█████████▉| 525M/528M [00:18<00:00, 32.2MB/s]    100%|██████████| 528M/528M [00:18<00:00, 30.2MB/s]




.. GENERATED FROM PYTHON SOURCE LINES 129-131

Normalize the features


.. GENERATED FROM PYTHON SOURCE LINES 131-139

.. code-block:: default

    num_features = feat1.shape[1]
    def l2norm(node_feat):
        return torch.nn.functional.local_response_norm(
            node_feat, node_feat.shape[1] * 2, alpha=node_feat.shape[1] * 2, beta=0.5, k=0)

    feat1 = l2norm(feat1)
    feat2 = l2norm(feat2)








.. GENERATED FROM PYTHON SOURCE LINES 140-142

Up-sample the features to the original image size


.. GENERATED FROM PYTHON SOURCE LINES 142-145

.. code-block:: default

    feat1_upsample = torch.nn.functional.interpolate(feat1, (obj_resize[1], obj_resize[0]), mode='bilinear')
    feat2_upsample = torch.nn.functional.interpolate(feat2, (obj_resize[1], obj_resize[0]), mode='bilinear')








.. GENERATED FROM PYTHON SOURCE LINES 146-148

Visualize the extracted CNN feature (dimensionality reduction via principle component analysis)


.. GENERATED FROM PYTHON SOURCE LINES 148-169

.. code-block:: default

    pca_dim_reduc = PCAdimReduc(n_components=3, whiten=True)
    feat_dim_reduc = pca_dim_reduc.fit_transform(
        np.concatenate((
            feat1_upsample.permute(0, 2, 3, 1).reshape(-1, num_features).numpy(),
            feat2_upsample.permute(0, 2, 3, 1).reshape(-1, num_features).numpy()
        ), axis=0)
    )
    feat_dim_reduc = feat_dim_reduc / np.max(np.abs(feat_dim_reduc), axis=0, keepdims=True) / 2 + 0.5
    feat1_dim_reduc = feat_dim_reduc[:obj_resize[0] * obj_resize[1], :]
    feat2_dim_reduc = feat_dim_reduc[obj_resize[0] * obj_resize[1]:, :]

    plt.figure(figsize=(8, 4))
    plt.subplot(1, 2, 1)
    plt.title('Image 1 with CNN features')
    plot_image_with_graph(img1, kpts1, A1)
    plt.imshow(feat1_dim_reduc.reshape(obj_resize[1], obj_resize[0], 3), alpha=0.5)
    plt.subplot(1, 2, 2)
    plt.title('Image 2 with CNN features')
    plot_image_with_graph(img2, kpts2, A2)
    plt.imshow(feat2_dim_reduc.reshape(obj_resize[1], obj_resize[0], 3), alpha=0.5)




.. image-sg:: /auto_examples/6.image_matching_by_QAP/images/sphx_glr_plot_image_matching_pytorch_003.png
   :alt: Image 1 with CNN features, Image 2 with CNN features
   :srcset: /auto_examples/6.image_matching_by_QAP/images/sphx_glr_plot_image_matching_pytorch_003.png
   :class: sphx-glr-single-img


.. rst-class:: sphx-glr-script-out

 .. code-block:: none


    <matplotlib.image.AxesImage object at 0x7fed5c18bf40>



.. GENERATED FROM PYTHON SOURCE LINES 170-172

Extract node features by nearest interpolation


.. GENERATED FROM PYTHON SOURCE LINES 172-177

.. code-block:: default

    rounded_kpts1 = torch.round(kpts1).to(dtype=torch.long)
    rounded_kpts2 = torch.round(kpts2).to(dtype=torch.long)
    node1 = feat1_upsample[0, :, rounded_kpts1[1], rounded_kpts1[0]].t() # shape: NxC
    node2 = feat2_upsample[0, :, rounded_kpts2[1], rounded_kpts2[0]].t() # shape: NxC








.. GENERATED FROM PYTHON SOURCE LINES 178-189

Build affinity matrix
----------------------
We follow the formulation of Quadratic Assignment Problem (QAP):

.. math::

    &\max_{\mathbf{X}} \ \texttt{vec}(\mathbf{X})^\top \mathbf{K} \texttt{vec}(\mathbf{X})\\
    s.t. \quad &\mathbf{X} \in \{0, 1\}^{n_1\times n_2}, \ \mathbf{X}\mathbf{1} = \mathbf{1}, \ \mathbf{X}^\top\mathbf{1} \leq \mathbf{1}

where the first step is to build the affinity matrix (:math:`\mathbf{K}`)


.. GENERATED FROM PYTHON SOURCE LINES 189-195

.. code-block:: default

    conn1, edge1 = pygm.utils.dense_to_sparse(A1)
    conn2, edge2 = pygm.utils.dense_to_sparse(A2)
    import functools
    gaussian_aff = functools.partial(pygm.utils.gaussian_aff_fn, sigma=1) # set affinity function
    K = pygm.utils.build_aff_mat(node1, edge1, conn1, node2, edge2, conn2, edge_aff_fn=gaussian_aff)








.. GENERATED FROM PYTHON SOURCE LINES 196-202

Visualization of the affinity matrix. For graph matching problem with :math:`N` nodes, the affinity matrix
has :math:`N^2\times N^2` elements because there are :math:`N^2` edges in each graph.

.. note::
    The diagonal elements are node affinities, the off-diagonal elements are edge features.


.. GENERATED FROM PYTHON SOURCE LINES 202-206

.. code-block:: default

    plt.figure(figsize=(4, 4))
    plt.title(f'Affinity Matrix (size: {K.shape[0]}$\\times${K.shape[1]})')
    plt.imshow(K.numpy(), cmap='Blues')




.. image-sg:: /auto_examples/6.image_matching_by_QAP/images/sphx_glr_plot_image_matching_pytorch_004.png
   :alt: Affinity Matrix (size: 100$\times$100)
   :srcset: /auto_examples/6.image_matching_by_QAP/images/sphx_glr_plot_image_matching_pytorch_004.png
   :class: sphx-glr-single-img


.. rst-class:: sphx-glr-script-out

 .. code-block:: none


    <matplotlib.image.AxesImage object at 0x7fed5c550ca0>



.. GENERATED FROM PYTHON SOURCE LINES 207-211

Solve graph matching problem by RRWM solver
-------------------------------------------
See :func:`~pygmtools.classic_solvers.rrwm` for the API reference.


.. GENERATED FROM PYTHON SOURCE LINES 211-213

.. code-block:: default

    X = pygm.rrwm(K, kpts1.shape[1], kpts2.shape[1])








.. GENERATED FROM PYTHON SOURCE LINES 214-216

The output of RRWM is a soft matching matrix. Hungarian algorithm is then adopted to reach a discrete matching matrix.


.. GENERATED FROM PYTHON SOURCE LINES 216-218

.. code-block:: default

    X = pygm.hungarian(X)








.. GENERATED FROM PYTHON SOURCE LINES 219-224

Plot the matching
------------------
The correct matchings are marked by green, and wrong matchings are marked by red. In this example, the nodes are
ordered by their ground truth classes (i.e. the ground truth matching matrix is a diagonal matrix).


.. GENERATED FROM PYTHON SOURCE LINES 224-236

.. code-block:: default

    plt.figure(figsize=(8, 4))
    plt.suptitle('Image Matching Result by RRWM')
    ax1 = plt.subplot(1, 2, 1)
    plot_image_with_graph(img1, kpts1, A1)
    ax2 = plt.subplot(1, 2, 2)
    plot_image_with_graph(img2, kpts2, A2)
    for i in range(X.shape[0]):
        j = torch.argmax(X[i]).item()
        con = ConnectionPatch(xyA=kpts1[:, i], xyB=kpts2[:, j], coordsA="data", coordsB="data",
                              axesA=ax1, axesB=ax2, color="red" if i != j else "green")
        plt.gca().add_artist(con)




.. image-sg:: /auto_examples/6.image_matching_by_QAP/images/sphx_glr_plot_image_matching_pytorch_005.png
   :alt: Image Matching Result by RRWM
   :srcset: /auto_examples/6.image_matching_by_QAP/images/sphx_glr_plot_image_matching_pytorch_005.png
   :class: sphx-glr-single-img





.. GENERATED FROM PYTHON SOURCE LINES 237-245

Solve by other solvers
-----------------------
We could also do a quick benchmarking of other solvers on this specific problem.

IPFP solver
^^^^^^^^^^^
See :func:`~pygmtools.classic_solvers.ipfp` for the API reference.


.. GENERATED FROM PYTHON SOURCE LINES 245-259

.. code-block:: default

    X = pygm.ipfp(K, kpts1.shape[1], kpts2.shape[1])

    plt.figure(figsize=(8, 4))
    plt.suptitle('Image Matching Result by IPFP')
    ax1 = plt.subplot(1, 2, 1)
    plot_image_with_graph(img1, kpts1, A1)
    ax2 = plt.subplot(1, 2, 2)
    plot_image_with_graph(img2, kpts2, A2)
    for i in range(X.shape[0]):
        j = torch.argmax(X[i]).item()
        con = ConnectionPatch(xyA=kpts1[:, i], xyB=kpts2[:, j], coordsA="data", coordsB="data",
                              axesA=ax1, axesB=ax2, color="red" if i != j else "green")
        plt.gca().add_artist(con)




.. image-sg:: /auto_examples/6.image_matching_by_QAP/images/sphx_glr_plot_image_matching_pytorch_006.png
   :alt: Image Matching Result by IPFP
   :srcset: /auto_examples/6.image_matching_by_QAP/images/sphx_glr_plot_image_matching_pytorch_006.png
   :class: sphx-glr-single-img





.. GENERATED FROM PYTHON SOURCE LINES 260-264

SM solver
^^^^^^^^^^^
See :func:`~pygmtools.classic_solvers.sm` for the API reference.


.. GENERATED FROM PYTHON SOURCE LINES 264-279

.. code-block:: default

    X = pygm.sm(K, kpts1.shape[1], kpts2.shape[1])
    X = pygm.hungarian(X)

    plt.figure(figsize=(8, 4))
    plt.suptitle('Image Matching Result by SM')
    ax1 = plt.subplot(1, 2, 1)
    plot_image_with_graph(img1, kpts1, A1)
    ax2 = plt.subplot(1, 2, 2)
    plot_image_with_graph(img2, kpts2, A2)
    for i in range(X.shape[0]):
        j = torch.argmax(X[i]).item()
        con = ConnectionPatch(xyA=kpts1[:, i], xyB=kpts2[:, j], coordsA="data", coordsB="data",
                              axesA=ax1, axesB=ax2, color="red" if i != j else "green")
        plt.gca().add_artist(con)




.. image-sg:: /auto_examples/6.image_matching_by_QAP/images/sphx_glr_plot_image_matching_pytorch_007.png
   :alt: Image Matching Result by SM
   :srcset: /auto_examples/6.image_matching_by_QAP/images/sphx_glr_plot_image_matching_pytorch_007.png
   :class: sphx-glr-single-img





.. GENERATED FROM PYTHON SOURCE LINES 280-291

NGM solver
^^^^^^^^^^^
See :func:`~pygmtools.neural_solvers.ngm` for the API reference.

.. note::
    The NGM solvers are pretrained on a different problem setting, so their performance may seem inferior.
    To improve their performance, you may change the way of building affinity matrices, or try finetuning
    NGM on the new problem.

The NGM solver pretrained on Willow dataset:


.. GENERATED FROM PYTHON SOURCE LINES 291-306

.. code-block:: default

    X = pygm.ngm(K, kpts1.shape[1], kpts2.shape[1], pretrain='willow')
    X = pygm.hungarian(X)

    plt.figure(figsize=(8, 4))
    plt.suptitle('Image Matching Result by NGM (willow pretrain)')
    ax1 = plt.subplot(1, 2, 1)
    plot_image_with_graph(img1, kpts1, A1)
    ax2 = plt.subplot(1, 2, 2)
    plot_image_with_graph(img2, kpts2, A2)
    for i in range(X.shape[0]):
        j = torch.argmax(X[i]).item()
        con = ConnectionPatch(xyA=kpts1[:, i], xyB=kpts2[:, j], coordsA="data", coordsB="data",
                              axesA=ax1, axesB=ax2, color="red" if i != j else "green")
        plt.gca().add_artist(con)




.. image-sg:: /auto_examples/6.image_matching_by_QAP/images/sphx_glr_plot_image_matching_pytorch_008.png
   :alt: Image Matching Result by NGM (willow pretrain)
   :srcset: /auto_examples/6.image_matching_by_QAP/images/sphx_glr_plot_image_matching_pytorch_008.png
   :class: sphx-glr-single-img


.. rst-class:: sphx-glr-script-out

 .. code-block:: none


    Downloading to /home/wzever/.cache/pygmtools/ngm_willow_pytorch.pt...

    Downloading to /home/wzever/.cache/pygmtools/ngm_willow_pytorch.pt...
    Warning: Network error. Retrying...
     HTTPSConnectionPool(host='huggingface.co', port=443): Max retries exceeded with url: /heatingma/pygmtools/resolve/main/ngm_willow_pytorch.pt (Caused by NameResolutionError("<urllib3.connection.HTTPSConnection object at 0x7fed5c21ef20>: Failed to resolve 'huggingface.co' ([Errno -3] Temporary failure in name resolution)"))

    Downloading to /home/wzever/.cache/pygmtools/ngm_willow_pytorch.pt...

    Downloading to /home/wzever/.cache/pygmtools/ngm_willow_pytorch.pt...

    Downloading to /home/wzever/.cache/pygmtools/ngm_willow_pytorch.pt...
    Warning: Network error. Retrying...
     HTTPSConnectionPool(host='huggingface.co', port=443): Max retries exceeded with url: /heatingma/pygmtools/resolve/main/ngm_willow_pytorch.pt (Caused by NameResolutionError("<urllib3.connection.HTTPSConnection object at 0x7fed5c21e8c0>: Failed to resolve 'huggingface.co' ([Errno -3] Temporary failure in name resolution)"))

    Downloading to /home/wzever/.cache/pygmtools/ngm_willow_pytorch.pt...




.. GENERATED FROM PYTHON SOURCE LINES 307-309

The NGM solver pretrained on VOC dataset:


.. GENERATED FROM PYTHON SOURCE LINES 309-323

.. code-block:: default

    X = pygm.ngm(K, kpts1.shape[1], kpts2.shape[1], pretrain='voc')
    X = pygm.hungarian(X)

    plt.figure(figsize=(8, 4))
    plt.suptitle('Image Matching Result by NGM (voc pretrain)')
    ax1 = plt.subplot(1, 2, 1)
    plot_image_with_graph(img1, kpts1, A1)
    ax2 = plt.subplot(1, 2, 2)
    plot_image_with_graph(img2, kpts2, A2)
    for i in range(X.shape[0]):
        j = torch.argmax(X[i]).item()
        con = ConnectionPatch(xyA=kpts1[:, i], xyB=kpts2[:, j], coordsA="data", coordsB="data",
                              axesA=ax1, axesB=ax2, color="red" if i != j else "green")
        plt.gca().add_artist(con)



.. image-sg:: /auto_examples/6.image_matching_by_QAP/images/sphx_glr_plot_image_matching_pytorch_009.png
   :alt: Image Matching Result by NGM (voc pretrain)
   :srcset: /auto_examples/6.image_matching_by_QAP/images/sphx_glr_plot_image_matching_pytorch_009.png
   :class: sphx-glr-single-img






.. rst-class:: sphx-glr-timing

   **Total running time of the script:** (0 minutes 29.307 seconds)


.. _sphx_glr_download_auto_examples_6.image_matching_by_QAP_plot_image_matching_pytorch.py:

.. only:: html

  .. container:: sphx-glr-footer sphx-glr-footer-example




    .. container:: sphx-glr-download sphx-glr-download-python

      :download:`Download Python source code: plot_image_matching_pytorch.py <plot_image_matching_pytorch.py>`

    .. container:: sphx-glr-download sphx-glr-download-jupyter

      :download:`Download Jupyter notebook: plot_image_matching_pytorch.ipynb <plot_image_matching_pytorch.ipynb>`


.. only:: html

 .. rst-class:: sphx-glr-signature

    `Gallery generated by Sphinx-Gallery <https://sphinx-gallery.github.io>`_
