{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n# Paddle Backend Example: Multi-Graph Matching\n\nThis example shows how to match multiple graphs. Multi-graph matching means that more than two graphs are jointly\nmatched.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# Author: Zetian Jiang <maple_jzt@sjtu.edu.cn>\n#         Ziao Guo <ziao.guo@sjtu.edu.cn>\n#         Wenzheng Pan <pwz1121@sjtu.edu.cn>\n#\n# License: Mulan PSL v2 License"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<div class=\"alert alert-info\"><h4>Note</h4><p>The following solvers are included in this example:\n\n    * :func:`~pygmtools.classic_solvers.rrwm` (classic solver)\n\n    * :func:`~pygmtools.multi_graph_solvers.cao` (classic solver)\n\n    * :func:`~pygmtools.multi_graph_solvers.mgm_floyd` (classic solver)</p></div>\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import os\nimport time\nimport math\nimport copy\nimport paddle as pd  # paddle backend\nimport itertools\nimport numpy as np\nimport pygmtools as pygm\nimport matplotlib.pyplot as plt  # for plotting\nimport scipy.io as sio  # for loading .mat file\nimport scipy.spatial as spa  # for Delaunay triangulation\n\nfrom PIL import Image\nfrom matplotlib.patches import ConnectionPatch # for plotting matching result\n\npygm.BACKEND = 'paddle'  # set default backend for pygmtools"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Load the images\nImages are from the Willow Object Class dataset (this dataset also available with the Benchmark of ``pygmtools``,\nsee :class:`~pygmtools.dataset.WillowObject`).\n\nThe images are resized to 256x256.\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "def load_image(pth, resize, n_outlier):\n    # load images\n    img = Image.open(pth + '.png')\n    # load key points' coordinates\n    kpts = pd.to_tensor(sio.loadmat(pth + '.mat')['pts_coord'])\n    kpts[0] = kpts[0] * resize[0] / img.size[0]\n    kpts[1] = kpts[1] * resize[1] / img.size[1]\n    img = img.resize(resize, resample=Image.BILINEAR)\n    # generate random outlier\n    if n_outlier != 0:\n        random_kpts = pd.rand((2, n_outlier))\n        random_kpts[0] = random_kpts[0] * resize[0]\n        random_kpts[1] = random_kpts[1] * resize[1]\n        kpts = pd.cat([kpts, random_kpts], axis=1)\n    # random shuffle the key points\n    perm = np.eye(kpts.shape[1])\n    # np.random.shuffle(perm)\n    # perm = pd.to_tensor(perm)\n    # kpts = pd.matmul(kpts, perm)\n    return img, kpts, perm\n\n\nobj_resize = (256, 256)\ndata_dir = '../data/mgm_data/Motorbike'\nn_images = 30\nn_outlier = 0\nimg_list = []\nkpts_list = []\nn_kpts_list = []\nperm_list = []\n\nfor root, ds, fs in os.walk(data_dir):\n    for i, f in enumerate(fs):\n        if f[-3:] == 'mat':\n            continue\n        if len(img_list) == n_images:\n            break\n        path = os.path.join(data_dir, f[:-4])\n        img, kpts, perm = load_image(pth=path, resize=obj_resize, n_outlier=n_outlier)\n        img_list.append(img)\n        kpts_list.append(kpts)\n        n_kpts_list.append(kpts.shape[1])\n        perm_list.append(perm)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Visualize the images and keypoints\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "def plot_image_with_graph(img, kpt, A=None):\n    plt.imshow(img)\n    plt.scatter(kpt[0], kpt[1], c='w', edgecolors='k')\n    if A is not None:\n        for idx in pd.nonzero(A, as_tuple=False):\n            plt.plot((kpt[0, idx[0]], kpt[0, idx[1]]), (kpt[1, idx[0]], kpt[1, idx[1]]), 'k-')\n\n\nplt.figure(figsize=(4 * n_images, 4))\nfor i in range(n_images):\n    plt.subplot(1, n_images, i + 1)\n    plt.title('Image {}'.format(i + 1))\n    plot_image_with_graph(img_list[i], kpts_list[i])\n# plt.savefig('image')\n# plt.close()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Build the graphs\nGraph structures are built based on the geometric structure of the keypoint set. In this example,\nwe refer to [Delaunay triangulation](https://en.wikipedia.org/wiki/Delaunay_triangulation).\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "def delaunay_triangulation(kpt):\n    d = spa.Delaunay(kpt.numpy().transpose())\n    A = pd.zeros((len(kpt[0]), len(kpt[0])))\n    for simplex in d.simplices:\n        for pair in itertools.permutations(simplex, 2):\n            A[pair] = 1\n    return A\n\n\nadj_list = []\nfor i in range(n_images):\n    A = delaunay_triangulation(kpts_list[i])\n    adj_list.append(A)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Build affinity matrix\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "def get_feature(n, points, adj):\n    \"\"\"\n    :param n: points # of graph\n    :param points: pd tensor, (n, 2)\n    :param adj: pd tensor, (n, n)\n    :return: edge feat, angle feat\n    \"\"\"\n    points_1 = points.reshape((n, 1, 2)).tile((1, n, 1))\n    points_2 = points.reshape((1, n, 2)).tile((n, 1, 1))\n    edge_feat = pd.sqrt(pd.sum((points_1 - points_2) ** 2, axis=2))\n    edge_feat = edge_feat / pd.max(edge_feat)\n    angle_feat = pd.atan((points_1[:, :, 1] - points_2[:, :, 1]) / (points_1[:, :, 0] - points_2[:, :, 0] + 1e-8))\n    angle_feat = 2 * angle_feat / math.pi\n\n    return edge_feat, angle_feat\n\n\ndef get_pair_affinity(edge_feat_1, angle_feat_1, edge_feat_2, angle_feat_2, adj1, adj2):\n    n1, n2 = edge_feat_1.shape[0], edge_feat_2.shape[0]\n    assert n1 == angle_feat_1.shape[0] and n2 == angle_feat_2.shape[0]\n\n    left_adj = adj1.reshape((n1, n1, 1, 1)).tile((1, 1, n2, n2))\n    right_adj = adj2.reshape((1, 1, n2, n2)).tile((n1, n1, 1, 1))\n    adj = left_adj * right_adj\n\n    left_edge_feat = edge_feat_1.reshape((n1, n1, 1, 1, -1)).tile((1, 1, n2, n2, 1))\n    right_edge_feat = edge_feat_2.reshape((1, 1, n2, n2, -1)).tile((n1, n1, 1, 1, 1))\n    edge_weight = pd.sqrt(pd.sum((left_edge_feat - right_edge_feat) ** 2, axis=-1))\n\n    left_angle_feat = angle_feat_1.reshape((n1, n1, 1, 1, -1)).tile((1, 1, n2, n2, 1))\n    right_angle_feat = angle_feat_2.reshape((1, 1, n2, n2, -1)).tile((n1, n1, 1, 1, 1))\n    angle_weight = pd.sqrt(pd.sum((left_angle_feat - right_angle_feat) ** 2, axis=-1))\n\n    affinity = edge_weight * 0.9 + angle_weight * 0.1\n    affinity = pd.exp(-affinity / 0.1) * adj\n    affinity = affinity.transpose((0, 2, 1, 3))\n\n    return affinity\n\n\ndef generate_affinity_matrix(n_points, points_list, adj_list):\n    m = len(n_points)\n    n_max = max(n_points)\n    affinity = pd.zeros((m, m, n_max, n_max, n_max, n_max))\n\n    edge_feat_list = []\n    angle_feat_list = []\n    for n, points, adj in zip(n_points, points_list, adj_list):\n        edge_feat, angle_feat = get_feature(n, points, adj)\n        edge_feat_list.append(edge_feat)\n        angle_feat_list.append(angle_feat)\n\n    for i, j in itertools.product(range(m), range(m)):\n        pair_affinity = get_pair_affinity(edge_feat_list[i],\n                                          angle_feat_list[i],\n                                          edge_feat_list[j],\n                                          angle_feat_list[j],\n                                          adj_list[i],\n                                          adj_list[j])\n        affinity[i, j] = pd.cast(pair_affinity, 'float32')\n\n    affinity = affinity.transpose((0, 1, 3, 2, 5, 4)).reshape((m, m, n_max * n_max, n_max * n_max))\n    return affinity\n\n\naffinity_mat = generate_affinity_matrix(n_kpts_list, kpts_list, adj_list)\n\nm = len(kpts_list)\nn = int(pd.max(pd.to_tensor(n_kpts_list)))\nns_src = pd.ones(m * m, dtype=int) * n\nns_tgt = pd.ones(m * m, dtype=int) * n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Calculate accuracy, consistency, and affinity\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "def cal_accuracy(mat, gt_mat, n):\n    m = mat.shape[0]\n    acc = 0\n    for i in range(m):\n        for j in range(m):\n            _mat, _gt_mat = mat[i, j], gt_mat[i, j]\n            row_sum = pd.sum(_gt_mat, axis=0)\n            col_sum = pd.sum(_gt_mat, axis=1)\n            row_idx = [k for k in range(n) if row_sum[k] != 0]\n            col_idx = [k for k in range(n) if col_sum[k] != 0]\n            # print(row_idx)\n            _mat = pd.index_select(_mat, pd.to_tensor(row_idx), axis=0)\n            _mat = pd.index_select(_mat, pd.to_tensor(col_idx), axis=1)\n            _gt_mat = pd.index_select(_gt_mat, pd.to_tensor(row_idx), axis=0)\n            _gt_mat = pd.index_select(_gt_mat, pd.to_tensor(col_idx), axis=1)\n            acc += 1 - pd.sum(pd.abs(_mat - _gt_mat)) / 2 / (n - n_outlier)\n    return acc / (m * m)\n\n\ndef cal_consistency(mat, gt_mat, m, n):\n    return pd.mean(get_batch_pc_opt(mat))\n\n\ndef cal_affinity(X, X_gt, K, m, n):\n    X_batch = X.reshape((-1, n, n))\n    X_gt_batch = X_gt.reshape((-1, n, n))\n    K_batch = K.reshape((-1, n * n, n * n))\n    affinity = get_batch_affinity(X_batch, K_batch)\n    affinity_gt = get_batch_affinity(X_gt_batch, K_batch)\n    return pd.mean(affinity / (affinity_gt + 1e-8))\n\n\ndef get_batch_affinity(X, K, norm=1):\n    \"\"\"\n    calculate affinity score\n    :param X: (b, n, n)\n    :param K: (b, n*n, n*n)\n    :param norm: normalization term\n    :return: affinity_score (b, 1, 1)\n    \"\"\"\n    b, n, _ = X.shape\n    vx = X.transpose((0, 2, 1)).reshape((b, -1, 1))  # (b, n*n, 1)\n    vxt = vx.transpose((0, 2, 1))  # (b, 1, n*n)\n    affinity = pd.bmm(pd.bmm(vxt, K), vx) / norm\n    return affinity\n\n\ndef get_single_affinity(X, K, norm=1):\n    \"\"\"\n    calculate affinity score\n    :param X: (n, n)\n    :param K: (n*n, n*n)\n    :param norm: normalization term\n    :return: affinity_score scale\n    \"\"\"\n    n, _ = X.shape\n    vx = X.transpose((0, 1)).reshape((-1, 1))\n    vxt = vx.transpose((0, 1))\n    affinity = pd.matmul(pd.matmul(vxt, K), vx) / norm\n    return affinity\n\n\ndef get_single_pc(X, i, j, Xij=None):\n    \"\"\"\n    :param X: (m, m, n, n) all the matching results\n    :param i: index\n    :param j: index\n    :param Xij: (n, n) matching\n    :return: the consistency of X_ij\n    \"\"\"\n    m, _, n, _ = X.shape\n    if Xij is None:\n        Xij = X[i, j]\n    pair_con = 0\n    for k in range(m):\n        X_combo = pd.matmul(X[i, k], X[k, j])\n        pair_con += pd.sum(pd.abs(Xij - X_combo)) / (2 * n)\n    return 1 - pair_con / m\n\n\ndef get_single_pc_opt(X, i, j, Xij=None):\n    \"\"\"\n    :param X: (m, m, n, n) all the matching results\n    :param i: index\n    :param j: index\n    :return: the consistency of X_ij\n    \"\"\"\n    m, _, n, _ = X.shape\n    if Xij is None:\n        Xij = X[i, j]\n    X1 = X[i, :].reshape((-1, n, n))\n    X2 = X[:, j].reshape((-1, n, n))\n    X_combo = pd.bmm(X1, X2)\n    pair_con = 1 - pd.sum(pd.abs(Xij - X_combo)) / (2 * n * m)\n    return pair_con\n\n\ndef get_batch_pc(X):\n    \"\"\"\n    :param X: (m, m, n, n) all the matching results\n    :return: (m, m) the consistency of X\n    \"\"\"\n    pair_con = pd.zeros((m, m))\n    for i in range(m):\n        for j in range(m):\n            pair_con[i, j] = get_single_pc_opt(X, i, j)\n    return pair_con\n\n\ndef get_batch_pc_opt(X):\n    \"\"\"\n    :param X: (m, m, n, n) all the matching results\n    :return: (m, m) the consistency of X\n    \"\"\"\n    m, _, n, _ = X.shape\n    X1 = X.reshape((m, 1, m, n, n)).tile((1, m, 1, 1, 1)).reshape((-1, n, n))  # X1[i, j, k] = X[i, k]\n    X2 = X.reshape((1, m, m, n, n)).tile((m, 1, 1, 1, 1)).transpose((0, 2, 1, 3, 4)).reshape((-1, n, n))  # X2[i, j, k] = X[k, j]\n    X_combo = pd.bmm(X1, X2).reshape((m, m, m, n, n))\n    X_ori = X.reshape((m, m, 1, n, n)).tile((1, 1, m, 1, 1))\n    pair_con = 1 - pd.sum(pd.abs(X_combo - X_ori), axis=(2, 3, 4)) / (2 * n * m)\n    return pair_con\n\n\ndef eval(mat, gt_mat, affinity, m, n):\n    acc = cal_accuracy(mat, gt_mat, n)\n    src = cal_affinity(mat, gt_mat, affinity, m, n)\n    con = cal_consistency(mat, gt_mat, m, n)\n    return acc, src, con"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Generate gt mat\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "gt_mat = pd.zeros((m, m, n, n))\nfor i in range(m):\n    for j in range(m):\n        gt_mat[i, j] = pd.to_tensor(np.matmul(perm_list[i].transpose((0, 1)), perm_list[j]), dtype='float32')\n# print(perm_list[0])\n# print(perm_list[1])\n# print(gt_mat[1, 2])\n# print(gt_mat[0, 1] - gt_mat[1, 0].transpose(0, 1))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Pairwise graph matching by RRWM\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "a = 0\nb = 12\ntic = time.time()\nrrwm_mat = pygm.classic_solvers.rrwm(affinity_mat.reshape((-1, n * n, n * n)), ns_src, ns_tgt)\nrrwm_mat = pygm.linear_solvers.hungarian(rrwm_mat)\ntoc = time.time()\nrrwm_mat = rrwm_mat.reshape((m, m, n, n))\nrrwm_acc, rrwm_src, rrwm_con = eval(rrwm_mat, gt_mat, affinity_mat, m, n)\nrrwm_tim = toc - tic\n\nplt.figure(figsize=(8, 4))\nplt.suptitle('Multi-Graph Matching Result by RRWM')\nax1 = plt.subplot(1, 2, 1)\nplot_image_with_graph(img_list[a], kpts_list[a], adj_list[a])\nax2 = plt.subplot(1, 2, 2)\nplot_image_with_graph(img_list[b], kpts_list[b], adj_list[b])\nX = rrwm_mat[a, b]\nfor i in range(X.shape[0]):\n    j = pd.argmax(X[i]).item()\n    con = ConnectionPatch(xyA=kpts_list[a][:, i], xyB=kpts_list[b][:, j], coordsA=\"data\", coordsB=\"data\",\n                          axesA=ax1, axesB=ax2, color=\"red\" if i != j else \"green\")\n    plt.gca().add_artist(con)\n# plt.savefig(\"RRWM.png\")\n# plt.close()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Multi graph matching: CAO-M\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "base_mat = copy.deepcopy(rrwm_mat)\ntic = time.time()\ncao_m_mat = pygm.multi_graph_solvers.cao(affinity_mat, base_mat, mode='memory')\ncao_m_mat = pygm.linear_solvers.hungarian(cao_m_mat.reshape((-1, n, n))).reshape((m, m, n, n))\ntoc = time.time()\ncao_m_acc, cao_m_src, cao_m_con = eval(cao_m_mat, gt_mat, affinity_mat, m, n)\ncao_m_tim = toc - tic + rrwm_tim\n\nplt.figure(figsize=(8, 4))\nplt.suptitle('Multi-Graph Matching Result by CAO-M')\nax1 = plt.subplot(1, 2, 1)\nplot_image_with_graph(img_list[a], kpts_list[a], adj_list[a])\nax2 = plt.subplot(1, 2, 2)\nplot_image_with_graph(img_list[b], kpts_list[b], adj_list[b])\nX = cao_m_mat[a, b]\nfor i in range(X.shape[0]):\n    j = pd.argmax(X[i]).item()\n    con = ConnectionPatch(xyA=kpts_list[a][:, i], xyB=kpts_list[b][:, j], coordsA=\"data\", coordsB=\"data\",\n                          axesA=ax1, axesB=ax2, color=\"red\" if i != j else \"green\")\n    plt.gca().add_artist(con)\n# plt.savefig(\"CAO-M.png\")\n# plt.close()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Multi graph matching: CAO-T\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "base_mat = copy.deepcopy(rrwm_mat)\ntic = time.time()\ncao_t_mat = pygm.multi_graph_solvers.cao(affinity_mat, base_mat, mode='time')\ncao_t_mat = pygm.linear_solvers.hungarian(cao_t_mat.reshape((-1, n, n))).reshape((m, m, n, n))\ntoc = time.time()\ncao_t_acc, cao_t_src, cao_t_con = eval(cao_t_mat, gt_mat, affinity_mat, m, n)\ncao_t_tim = toc - tic + rrwm_tim\n\nplt.figure(figsize=(8, 4))\nplt.suptitle('Multi-Graph Matching Result by CAO-T')\nax1 = plt.subplot(1, 2, 1)\nplot_image_with_graph(img_list[a], kpts_list[a], adj_list[a])\nax2 = plt.subplot(1, 2, 2)\nplot_image_with_graph(img_list[b], kpts_list[b], adj_list[b])\nX = cao_t_mat[a, b]\nfor i in range(X.shape[0]):\n    j = pd.argmax(X[i]).item()\n    con = ConnectionPatch(xyA=kpts_list[a][:, i], xyB=kpts_list[b][:, j], coordsA=\"data\", coordsB=\"data\",\n                          axesA=ax1, axesB=ax2, color=\"red\" if i != j else \"green\")\n    plt.gca().add_artist(con)\n# plt.savefig(\"CAO-T.png\")\n# plt.close()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Multi graph matching: MGM-Floyd-M\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "base_mat = copy.deepcopy(rrwm_mat)\ntic = time.time()\nfloyd_m_mat = pygm.multi_graph_solvers.mgm_floyd(affinity_mat, base_mat, param_lambda=0.4, mode='memory')\nfloyd_m_mat = pygm.linear_solvers.hungarian(floyd_m_mat.reshape((-1, n, n))).reshape((m, m, n, n))\ntoc = time.time()\nfloyd_m_acc, floyd_m_src, floyd_m_con = eval(floyd_m_mat, gt_mat, affinity_mat, m, n)\nfloyd_m_tim = toc - tic + rrwm_tim\n\nplt.figure(figsize=(8, 4))\nplt.suptitle('Multi-Graph Matching Result by Floyd-M')\nax1 = plt.subplot(1, 2, 1)\nplot_image_with_graph(img_list[a], kpts_list[a], adj_list[a])\nax2 = plt.subplot(1, 2, 2)\nplot_image_with_graph(img_list[b], kpts_list[b], adj_list[b])\nX = floyd_m_mat[a, b]\nfor i in range(X.shape[0]):\n    j = pd.argmax(X[i]).item()\n    con = ConnectionPatch(xyA=kpts_list[a][:, i], xyB=kpts_list[b][:, j], coordsA=\"data\", coordsB=\"data\",\n                          axesA=ax1, axesB=ax2, color=\"red\" if i != j else \"green\")\n    plt.gca().add_artist(con)\n# plt.savefig(\"Floyd-M.png\")\n# plt.close()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Multi graph matching: MGM-Floyd-T\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "base_mat = copy.deepcopy(rrwm_mat)\ntic = time.time()\nfloyd_t_mat = pygm.multi_graph_solvers.mgm_floyd(affinity_mat, base_mat, param_lambda=0.6, mode='time')\nfloyd_t_mat = pygm.linear_solvers.hungarian(floyd_t_mat.reshape((-1, n, n))).reshape((m, m, n, n))\ntoc = time.time()\nfloyd_t_acc, floyd_t_src, floyd_t_con = eval(floyd_t_mat, gt_mat, affinity_mat, m, n)\nfloyd_t_tim = toc - tic + rrwm_tim\n\nplt.figure(figsize=(8, 4))\nplt.suptitle('Multi-Graph Matching Result by Floyd-T')\nax1 = plt.subplot(1, 2, 1)\nplot_image_with_graph(img_list[a], kpts_list[a], adj_list[a])\nax2 = plt.subplot(1, 2, 2)\nplot_image_with_graph(img_list[b], kpts_list[b], adj_list[b])\nX = floyd_t_mat[a, b]\nfor i in range(X.shape[0]):\n    j = pd.argmax(X[i]).item()\n    con = ConnectionPatch(xyA=kpts_list[a][:, i], xyB=kpts_list[b][:, j], coordsA=\"data\", coordsB=\"data\",\n                          axesA=ax1, axesB=ax2, color=\"red\" if i != j else \"green\")\n    plt.gca().add_artist(con)\n# plt.savefig(\"Floyd-T.png\")\n# plt.close()"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.17"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}